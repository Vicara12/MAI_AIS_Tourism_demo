{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e53474fb",
   "metadata": {},
   "source": [
    "# GreenExplorer MCDA Pipeline Demo\n",
    "A minimal, end‑to‑end notebook that shows how to:\n",
    "1. Load the tourism CSVs already in your repo.\n",
    "2. (Optionally) call the ChatGPT API to enrich each POI with the six sustainability indicators *z₁–z₆*.\n",
    "3. Build an ELECTRE‑III decision matrix with **pyDecision** and get a ranking.\n",
    "4. Refine the non‑dominated kernel with a soft‑AND Logic‑Scoring‑of‑Preference (LSP) utility.\n",
    "5. Display the top‑k recommendations.\n",
    "\n",
    "> ✨ **Tip for class projects** – treat this notebook as a scaffold: run the cells, read the comments, then plug in your real indicator functions and UI.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15b6d3",
   "metadata": {},
   "source": [
    "## 📦 Install & import the specialised libraries\n",
    "Uncomment the first cell the **first time** you run the notebook or whenever you rebuild the Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789de1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pandas as pd, numpy as np\n",
    "from dataloader import readTourismData\n",
    "\n",
    "# MCDA libraries\n",
    "from pyDecision.algorithm import electre_iii\n",
    "from pymcdm.helpers import rankdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a91dc9",
   "metadata": {},
   "source": [
    "### 1️⃣ Load the demo POI corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readTourismData('../data')   # adjust path if you moved the notebook\n",
    "print(f'Total POIs loaded: {len(df):,}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ae089e",
   "metadata": {},
   "source": [
    "### 2️⃣ Generate/attach the six sustainability indicators *(z₁–z₆)*\n",
    "Below is a **placeholder** that shows how you *could* call the ChatGPT API in batch‑mode.\n",
    "Replace the prompt with your own indicator derivation logic (API, heuristics, sensors, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd, json, os, time, random\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a sustainability analyst.  For the Point-of-Interest below,\n",
    "return ONLY valid JSON with keys z1–z6 (floats 0–1).\n",
    "\n",
    "Definitions (copy exactly):\n",
    "• z1 = estimated CO2-kg per individual visit (lower = greener).\n",
    "• z2 = current_visitors / carrying_capacity (lower = less crowded).\n",
    "• z3 = entropy-based seasonality balance (higher = steadier flow).\n",
    "• z4 = proportion of revenue retained locally (higher = better).\n",
    "• z5 = crowd-adjusted heritage fragility (lower = safer for culture).\n",
    "• z6 = overall physical & sensory accessibility (higher = inclusive).\n",
    "\n",
    "POI:\n",
    "Name: {name}\n",
    "Category: {category}\n",
    "Lat,Lon: {lat}, {lon}\n",
    "Known sustainability proxy (0-1): {sustainability}\n",
    "Popularity score (0-1): {popularity}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_MSG = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a strict JSON generator. Output only valid JSON.\"\n",
    "}\n",
    "\n",
    "def gpt_enrich_row(row):\n",
    "    prompt = PROMPT_TEMPLATE.format(**row)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[SYSTEM_MSG, {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.1,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "def enrich_dataframe(df):\n",
    "    records = []\n",
    "    for _, r in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            records.append(gpt_enrich_row(r))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Skipped {r['name']}: {e}\")\n",
    "            records.append({f\"z{i}\": None for i in range(1, 7)})\n",
    "    return pd.concat([df.reset_index(drop=True),\n",
    "                      pd.DataFrame(records)], axis=1)\n",
    "\n",
    "# usage\n",
    "df = readTourismData(\"../data\")\n",
    "df = enrich_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CELL ▒▒ Save enriched data ▒▒─────────────────────────────────────────────\n",
    "# 1) master file with every POI + z-indicators\n",
    "master_path = \"../data/poi_all_enriched.csv\"\n",
    "df.to_csv(master_path, index=False)\n",
    "print(f\"✅  Master CSV written → {master_path}  ({len(df):,} rows)\")\n",
    "\n",
    "# 2) one CSV per municipality (keeps the original naming convention)\n",
    "for muni, sub in df.groupby(\"municipality\"):\n",
    "    fname = f\"../data/poi_{muni}_30_enriched.csv\"\n",
    "    sub.to_csv(fname, index=False)\n",
    "    print(\" • Saved\", fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33399e8",
   "metadata": {},
   "source": [
    "### 3️⃣ Build the ELECTRE‑III decision matrix\n",
    "We use **pyDecision** because it already implements the full ELECTRE family (I–TRI).\n",
    "Weights, thresholds (q/p/v) and the λ‑cut come straight out of the research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32baa7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from pyDecision.algorithm import electre_iii\n",
    "\n",
    "# 1 ── criteria present in the dataframe\n",
    "criteria = [f\"z{i}\" for i in range(1, 8)]\n",
    "\n",
    "# 2 ── keep only rows that have the full indicator set\n",
    "df_valid = df.dropna(subset=criteria).copy()\n",
    "print(f\"using {len(df_valid)} / {len(df)} rows with full indicators\")\n",
    "\n",
    "# 3 ── decision matrix (invert the three COST criteria → benefit form)\n",
    "M = df_valid[criteria].to_numpy(float)\n",
    "\n",
    "cost_idx = [0, 1, 4]                    # z1 (CO₂), z2 (overtourism), z5\n",
    "M[:, cost_idx] = 1.0 - M[:, cost_idx]   # bigger = better for everything\n",
    "\n",
    "# 4 ── ELECTRE-III parameters (same semantics as in the paper)\n",
    "Q = np.full(7, 0.05)                    # indifference threshold\n",
    "P = np.full(7, 0.20)                    # preference threshold\n",
    "V = np.full(7, 0.50)                    # veto threshold\n",
    "\n",
    "W = np.array([                          # weights from Table 6 (sum = 1)\n",
    "    0.15, 0.12, 0.08,   # P1  Environment\n",
    "    0.25,               # P2  Socio-economic\n",
    "    0.20,               # P3  Culture\n",
    "    0.10, 0.10 ])       # P4  Accessibility + Preference-fit\n",
    "\n",
    "# 5 ── run ELECTRE-III\n",
    "glob_C, cred, rank_D, *_ = electre_iii(M, P=P, Q=Q, V=V, W=W, graph=False)\n",
    "\n",
    "# 6 ── convert labels “a1 … aN” → original dataframe indices\n",
    "rank_map = {}                                 # df index → ordinal rank\n",
    "\n",
    "for pos, tied_block in enumerate(rank_D, start=1):   # rank_D is descending\n",
    "    labels = [lbl.strip() for lbl in tied_block.split(';')]\n",
    "    for lbl in labels:                               # unpack ties\n",
    "        alt_idx = int(lbl[1:]) - 1                   # \"a19\" → 18\n",
    "        df_index = df_valid.index[alt_idx]           # original row label\n",
    "        rank_map[df_index] = pos                     # same rank for all ties\n",
    "\n",
    "# 7 ── write back\n",
    "df[\"electre_rank\"] = np.nan\n",
    "df.loc[list(rank_map.keys()), \"electre_rank\"] = pd.Series(rank_map, dtype=float)\n",
    "\n",
    "print(\"✅ electre_rank filled for\",\n",
    "      df[\"electre_rank\"].notna().sum(), \"rows\")\n",
    "df.sort_values(\"electre_rank\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6558422",
   "metadata": {},
   "source": [
    "### 4️⃣ Soft‑AND LSP utility inside the non‑dominated kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ee8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CELL ▒▒ ELECTRE outranking – top-20 only ▒▒────────────────────────\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "MAX_ALTS = 20        # how many individual POIs to show\n",
    "\n",
    "# helper: \"a17\" -> POI name at that position\n",
    "def alt_to_name(label: str) -> str:\n",
    "    idx = int(label.strip()[1:]) - 1          # \"a17\" -> 16\n",
    "    return df_valid.loc[df_valid.index[idx], \"name\"]\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Build tiers until we accumulate MAX_ALTS alternatives\n",
    "tiers, alt_count = [], 0\n",
    "for block in rank_D:                           # rank_D is descending\n",
    "    if alt_count >= MAX_ALTS:\n",
    "        break\n",
    "    raw_labels = [tok.strip() for tok in block.split(\";\") if tok.strip()]\n",
    "    names      = [alt_to_name(tok) for tok in raw_labels]\n",
    "    # if adding this whole tier exceeds MAX_ALTS, truncate it\n",
    "    if alt_count + len(names) > MAX_ALTS:\n",
    "        names = names[: MAX_ALTS - alt_count]\n",
    "    tiers.append(\"; \".join(names))\n",
    "    alt_count += len(names)\n",
    "\n",
    "print(f\"Plotting {alt_count} alternatives across {len(tiers)} tiers\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Vertical digraph: node0 (best) -> node1 -> ...\n",
    "G = nx.DiGraph()\n",
    "for i, txt in enumerate(tiers):\n",
    "    G.add_node(i, label=txt)\n",
    "    if i < len(tiers) - 1:\n",
    "        G.add_edge(i, i + 1)\n",
    "\n",
    "pos = {i: (0, -i) for i in range(len(tiers))}\n",
    "\n",
    "plt.figure(figsize=(9, 1.2 * len(tiers)))\n",
    "nx.draw_networkx_nodes(G, pos, node_color=\"#c8f4d0\", node_size=2200)\n",
    "nx.draw_networkx_edges(G, pos, arrowstyle=\"->\", arrowsize=14)\n",
    "nx.draw_networkx_labels(\n",
    "    G, pos,\n",
    "    labels={i: lbl for i, lbl in G.nodes(data=\"label\")},\n",
    "    font_size=8, verticalalignment=\"center\", horizontalalignment=\"center\"\n",
    ")\n",
    "plt.title(\"ELECTRE-III Outranking Graph – Top 20 POIs\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CELL ▒▒ LSP contribution + explanation ▒▒───────────────────────────\n",
    "import json, matplotlib.pyplot as plt, pandas as pd, numpy as np\n",
    "\n",
    "rho = 0.5\n",
    "criteria  = [f\"z{i}\" for i in range(1, 8)]\n",
    "crit_names = [\"CO₂\", \"Overtourism\", \"Seasonality\",\n",
    "              \"Local-eco\", \"Cultural-fragility\",\n",
    "              \"Accessibility\", \"Pref-fit\"]      # for readability\n",
    "\n",
    "def lsp_parts(row):\n",
    "    \"\"\"Return (U, contrib_vector) for a single row.\"\"\"\n",
    "    parts = weights * (row[criteria].values.astype(float) ** rho)\n",
    "    U     = (parts.sum()) ** (1 / rho)\n",
    "    return U, parts\n",
    "\n",
    "records = []\n",
    "for idx, r in kernel.iterrows():\n",
    "    U, parts = lsp_parts(r)\n",
    "    pct = parts / parts.sum() * 100\n",
    "    top_pos = crit_names[int(pct.argmax())]\n",
    "    top_neg = crit_names[int(pct.argmin())]\n",
    "    natural = (f\"{r['name']} scores {U:.3f}. \"\n",
    "               f\"Main positive driver: {top_pos} ({pct.max():.1f}% of utility). \"\n",
    "               f\"Least contributing: {top_neg} ({pct.min():.1f}%).\")\n",
    "    records.append({\n",
    "        \"name\": r[\"name\"],\n",
    "        \"U_LSP\": U,\n",
    "        \"criterion_contribs\": json.dumps(\n",
    "            {n: round(p, 3) for n, p in zip(crit_names, pct)}\n",
    "        ),\n",
    "        \"top_positive\": top_pos,\n",
    "        \"top_negative\": top_neg,\n",
    "        \"natural_lang\": natural,\n",
    "    })\n",
    "\n",
    "explanations = pd.DataFrame(records)\n",
    "display(explanations.head(5))          # quick peek in notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cec964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a POI to visualise\n",
    "poi = explanations.iloc[0][\"name\"]\n",
    "\n",
    "row = kernel[kernel[\"name\"] == poi].iloc[0]\n",
    "U, parts = lsp_parts(row)\n",
    "pct = parts / parts.sum() * 100\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.barh(crit_names, pct)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(f\"LSP contribution breakdown – {poi}\\nU={U:.3f}\")\n",
    "plt.xlabel(\"% utility share\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1356df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CELL ▒▒ Clean pair-wise & global explanations (utility deltas) ▒▒───\n",
    "EPS = 0.5          # minimum share (percentage-points) to mention\n",
    "N_TERMS = 3        # bullets per list\n",
    "\n",
    "# Pre-compute Δ-utility (% share) for every POI in kernel\n",
    "delta_pct = {}\n",
    "for idx, row in kernel.iterrows():\n",
    "    contrib = weights * (row[criteria].values.astype(float) ** rho)\n",
    "    pct     = contrib / contrib.sum() * 100\n",
    "    delta_pct[idx] = pct\n",
    "\n",
    "idx2name   = kernel[\"name\"].to_dict()\n",
    "sorted_idx = kernel.sort_values(\"U_LSP\", ascending=False).index.tolist()\n",
    "\n",
    "def explain_pair(idx_a, idx_b, eps=EPS, n_terms=N_TERMS) -> str:\n",
    "    \"\"\"Natural-language why-A-beats-B explanation using +/- gaps.\"\"\"\n",
    "    pa, pb   = delta_pct[idx_a], delta_pct[idx_b]\n",
    "    diff     = pa - pb                          # + favours A\n",
    "    adv_idx  = [j for j in diff.argsort()[::-1] if diff[j] >  eps][:n_terms]\n",
    "    lag_idx  = [j for j in diff.argsort()       if diff[j] < -eps][:n_terms]\n",
    "\n",
    "    if not adv_idx and not lag_idx:\n",
    "        return (f\"### {idx2name[idx_a]} vs {idx2name[idx_b]}\\n\"\n",
    "                \"Scores are practically tied on every criterion \"\n",
    "                f\"(all gaps ≤ {eps} pp).\")\n",
    "\n",
    "    lines = [f\"### Why **_{idx2name[idx_a]}_** outranks **_{idx2name[idx_b]}_**\"]\n",
    "\n",
    "    for j in adv_idx:\n",
    "        lines.append(f\"• **{crit_names[j]}** contributes more \"\n",
    "                     f\"({pa[j]:.1f}% vs {pb[j]:.1f}%).\")\n",
    "    for j in lag_idx:\n",
    "        lines.append(f\"• Trades off lower **{crit_names[j]}** \"\n",
    "                     f\"({pa[j]:.1f}% vs {pb[j]:.1f}%).\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Example: top-1 vs top-2\n",
    "print(explain_pair(sorted_idx[0], sorted_idx[1]))\n",
    "\n",
    "def global_summary(top_k=10, eps=EPS):\n",
    "    \"\"\"One-liner per consecutive pair of the top-k ranked POIs.\"\"\"\n",
    "    out = []\n",
    "    for i in range(min(top_k - 1, len(sorted_idx) - 1)):\n",
    "        a, b = sorted_idx[i], sorted_idx[i + 1]\n",
    "        pa, pb = delta_pct[a], delta_pct[b]\n",
    "        diff   = pa - pb\n",
    "        mask   = np.abs(diff) > eps\n",
    "        if not mask.any():\n",
    "            key = f\"no single standout factor (> {eps} pp)\"\n",
    "        else:\n",
    "            j = np.argmax(np.where(mask, diff, -np.inf))\n",
    "            direction = \"higher\" if diff[j] > 0 else \"lower\"\n",
    "            key = (f\"{direction} **{crit_names[j]}** \"\n",
    "                   f\"({pa[j]:.1f}% vs {pb[j]:.1f}%)\")\n",
    "        out.append(f\"{i+1}>{i+2} – _{idx2name[a]}_ over _{idx2name[b]}_: {key}.\")\n",
    "    return out\n",
    "\n",
    "print(*global_summary(10), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa27833",
   "metadata": {},
   "source": [
    "### 5️⃣ Visualise the top‑k POIs on a map\n",
    "Streamlit already does this in your current `main.py`, but here’s a one‑liner with **folium** if you want to stay in‑notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b53b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install folium --quiet\n",
    "import folium, webbrowser, tempfile, uuid\n",
    "from fastai.imports import *\n",
    "\n",
    "m = folium.Map(location=[41.3851, 2.1734], zoom_start=6)\n",
    "top = kernel.head(15)\n",
    "for _, r in top.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        [r['lat'], r['lon']],\n",
    "        radius=6,\n",
    "        popup=f\"{r['name']} — U={r['U_LSP']:.2f}\",\n",
    "        fill=True\n",
    "    ).add_to(m)\n",
    "\n",
    "temp_path = Path(tempfile.gettempdir()) / f\"greenexplorer_{uuid.uuid4().hex}.html\"\n",
    "m.save(temp_path)\n",
    "webbrowser.open(temp_path.as_uri())\n",
    "print(f\"Map saved to {temp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d95dd",
   "metadata": {},
   "source": [
    "---\n",
    "**You’re all set!**\n",
    "\n",
    "*Next steps*\n",
    "1. Wire this notebook into your Streamlit UI (call the functions in `src/`).\n",
    "2. Replace the random indicator generator with real data pipelines or the ChatGPT enrichment.\n",
    "3. Plug the user/group preference vector into `z7`.\n",
    "4. Tune the ELECTRE thresholds & weights, then run the user study. :rocket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca777ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
